.. _nabyes1-spec:

入力データとクラスの仕様
========================

単純ベイズ法を実装するために，入力データと，単純ベイズ法のクラスの仕様を定めます．

.. _nabyes1-spec-input:

入力データの仕様
----------------

:ref:`nbayes1-nbayes` では，単純ベイズの入力データは， :math:`\mathcal{D}=\{\mathbf{x}_i, y_i\},\,i=1,\ldots,N` であると述べました．
これを NumPy 配列で表現します．

入力の特徴ベクトル :math:`\mathbf{x}_i` は，長さが :math:`K` のベクトルです．
NumPy配列の多様な配列操作を利用できるようにするため，このベクトルを :math:`N` 個集めたものをまとめて一つの :math:`N \times K` の大きさの行列で表現します．
すなわち，入力特徴ベクトル集合を表す変数 :obj:`X` は2次元なので， :attr:`ndim` 属性は ``2`` に， :attr:`shape` 属性は ``(N, K)`` とします．
また，特徴は全て二値変数に制限したので，配列 :obj:`X` の要素は 0 か 1 の整数となり，変数 :obj:`X` の要素の型である :attr:`dtype` 属性は整数型となります．

もう一方の入力のクラス変数 :math:`y_i` は， 0 か 1 の整数をとるスカラーです．
これを :math:`N` 個集めて，長さ :math:`N` の1次元配列 :obj:`y` で表現します．
この変数の属性 :attr:`ndim` ， :attr:`shape` ，および :attr:`dtype` 属性は，それぞれ ``2`` ， ``N`` ，および整数型となります．
この特徴ベクトル :obj:`X` とクラス変数 :obj:`y` との組が，学習時の入力となります．

パラメータの学習後，クラスが未知である特徴ベクトル :math:`\mathbf{x}_\mathrm{new}` のクラスを予測する場合の入力を考えます．
この特徴ベクトルも， :math:`M` 個まとめて与えられるものとし，それらを集めて :attr:`shape` 属性が (M, K) の変数 ``X`` で表すことにします．
予測時には，クラス変数はないので，この変数 ``X`` のみが入力となります．

.. _nabyes1-spec-class:

単純ベイズクラスの仕様
----------------------

次に，単純ベイズ法のためのクラスを設計します．
機械学習のアルゴリズムは，関数を用いるだけでも実装できますが，クラスを定義して実装することには，次のような利点があります．

* クラスの継承を利用して，モデルと予測メソッドだけを共有し，学習アルゴリズムだけを変えて部分的に改良するといったことが容易になります．
* :mod:`cPickle` などの，オブジェクトのシリアライズを利用して，学習したモデルのオブジェクトを，ファイルに保存しておくことで再利用できるようになります．

.. index:: scikit-learn

このチュートリアルでは，Python の機械学習パッケージ scikit-learn のAPI仕様 ( `APIs of scikit-learn objects <http://scikit-learn.org/stable/developers/index.html#apis-of-scikit-learn-objects>`_ ) に従ってクラスを設計します．
主な仕様は次のとおりです．

* データに依存しないアルゴリズムのパラメータは，クラスのコンストラクタの引数で指定する．
* 学習は :meth:`fit` メソッドで行う．
  訓練データと，データに依存したパラメータを，このメソッドの引数で指定する．
* 予測は :meth:`predict` メソッドで行う．
  新規の入力データを，このメソッドの引数で指定する．
* モデルのデータへのあてはめの良さの評価は， :meth:`score` メソッドで行う．
  評価対象のデータを，このメソッドの引数で指定する．
* 次元削減などのデータ変換は， :meth:`transform` メソッドで行う．

単純ベイズクラスの名前は :class:`NaiveBayes1` とします．
単純ベイズは教師あり学習であるため，パラメータの初期化を行うコンストラクタ，学習を行う :meth:`fit` メソッド，および予測を行う :meth:`predict` メソッドが最低限必要になります．

.. index::
   single: NaiveBayes1

まず，クラスの定義は次のとおりです．

.. code-block:: python

    class NaiveBayes1(object):
        """
        Naive Bayes class (1)
        """

ここで実装する単純ベイズクラスは，他のクラスを継承してその機能を利用する必要はないので，親クラスを :class:`object` とします．

コンストラクタの定義は次のとおりです．

.. code-block:: python

    def __init__(self):
        """
        Constructor
        """
        self.pY_ = None
        self.pXgY_ = None

:ref:`nbayes1-nbayes` の単純ベイズには，データに依存しないパラメータはないので，コンストラクタ :meth:`__init__` の引数は :obj:`self` だけです．
このコンストラクタの中では，学習すべきモデルのパラメータを格納するためのインスタンス変数を作成します．
:ref:`nbayes1-nbayes` の式(4)と(5)がモデルのパラメータです．
式(4)の :math:`\Pr[y]` はインスタンス変数 :obj:`self.pY_` に，式(5)の :math:`\Pr[x_j | y]` はインスタンス変数 :obj:`self.pXgY_` に格納します．
モデルパラメータを格納するインスタンス変数の名前は，scikit-learn の慣習に従って，その最後を ``_`` としました．
これらのモデルパラメータを格納する配列の大きさは，データに依存して決まるため，コンストラクタでは :obj:`None` で初期化します．

学習を行う :meth:`fit` メソッドの枠組みは次のとおりです．

.. code-block:: python

    def fit(self, X, y):
        """
        Fitting model
        """
        pass

:meth:`fit` メソッドの引数 :obj:`X` と :obj:`y` は，前節で述べたように訓練データと特徴ベクトルとクラスラベルの集合を表します．
具体的な学習アルゴリズムの実装は :ref:`nbayes1-fit1` で述べます．

クラスを予測する :meth:`predict` メソッドの枠組みは次のとおりです．

.. code-block:: python

    def predict(self, X):
        """
        Predict class
        """
        pass

この :obj:`predict` メソッドの引数 :obj:`X` は，前節で述べたように未知のデータを表します．
このメソッドの具体的な実装は :ref:`nbayes1-predict` で述べます．
